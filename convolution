Convolution:

當一個Function輸入一個系統(也是Function)後, 會輸出為另一個Function. 而, 該輸出的Function為每個輸入訊號所產生的當下效應及殘留效應. 為了表示這樣的關係, 及將其稱呼為Convolue.

https://stackoverflow.com/questions/17337332/why-convolution-is-required-or-what-is-the-philosophy-behind-convolution
If you refer to the wikipedia article regarding LTI system theory you will see that the impulse response h(t) dictates how the system responds to an impulse d(t). We also know that the equation for the output of a system is y(t) = h(t) * x(t) in the time domain. Where y(t) is the output, h(t) is the impulse response, x(t) is the input. The symbol * refers to the convolution of h(t) and x(t)

In the frequency domain (by performing the Laplace transform), we know that Y(s) = H(s)X(s), thus the output response to the input X(s) is the Multiplication of the transfer function H(s) and the input X(s).


兩個Function做Convolue, 有兩種表示方法:
http://blog.csdn.net/bitcarmanlee/article/details/54729807
1. 
x[0, 1, 2]分別去乘y[0], 落在axis為0, 1, 2
x[0, 1, 2]分別去乘y[1], 落在axis為1, 2, 3
x[0, 1, 2]分別去乘y[2], 落在axis為2, 3, 4
在axis去做各點相加, 其結果即為Convolution
以axis為0來說, 那時, 只有x[0]和y[0]的乘積
但, 到了axis為1, 則除了有x[1]和y[0], 也有x[0]和y[1]. 其x[1]和y[0], 是新輸入的乘積. 其x[0]和y[1], 則是之前x[0]在系統內的殘留效應, 而效應的大小是y[1].
以此法, 則是一次各別算, 當x[0]時, 和y[n]的各別乘績. 當x[1]時, 和y[n]的各別乘績. 但, 如要知道axis 0, 1, 2的結果, 則需再相加. 從圖示上, 也較難看出, 在axis 0, 1, 2時的各別效應.

2. 
http://blog.csdn.net/zyex1108/article/details/45397637
另外一種, 則是Reflect再相乘. 差別在於, 透過這種方式, 可以一次算出系統分別在axis 0, 1, or 2的各別所有反應.
也就是說, 系統function轉折, 
看axis 0時, 剛好會是x[0]和y[0]的乘積
看axis 1時, 剛好會是x[0]和y[1]的乘積, 和x[1]和y[0]的乘積. 
以此法, 可以在圖示看到, 當axis 0時, x[0]和y[0]有乘積, 在axis 1時, x[0]和y[1]有overlay, x[1]和y[0]有overaly, 也就是在axis 0時, 系統的output是要考慮兩者的影響.

https://www.quora.com/How-can-I-explain-in-a-simple-manner-what-convolution-is-and-why-it-is-important/answer/Mahesh-C-Shastry
https://www.quora.com/Digital-Signal-Processing/How-can-I-explain-in-a-simple-manner-what-convolution-is-and-why-it-is-important/answer/Mahesh-C-Shastry?share=1&srid=pd9d
https://www.quora.com/Digital-Signal-Processing/How-can-I-explain-in-a-simple-manner-what-convolution-is-and-why-it-is-important/answer/Raeed-Chowdhury?share=1&srid=hj0Y
https://www.quora.com/Digital-Signal-Processing-How-do-you-explain-without-doing-any-calculation-that-convolution-in-time-domain-should-imply-multiplication-in-frequency-domain
In a linear, time-invariant system, you can characterize the entire system with a single signal called the impulse response. This impulse response is the output of the system when the input is a simple impulse at time 0.
一個線性非時變的系統, 不論是連續或離散, 都可以用Impulse Respone來描述整個系統. 基本上, 是指該系統本身是一連串的Impulse Response組成的. 而, 組成的樣子會是多根高低不一的Impulse Respone.
另外, 輸入的訊號也可以表達成多個Impulse Signal的組合. 
輸入Impuse Signal, 在一一去乘上系統各階段的Impulse Response, 其結果即為系統的各階段Response.
如輸入訊號只為一個impulse signal, 但, 由Impulse Response描述的系統在0, 1, 2都各有Response, 則, 該輸入訊號輸入後, 系統在0, 1, 2得到的圖形和原系統的Impluse Response相同. 
系統的Impulse Response, 應該是以單位Impulse Signal輸入後, 在0, 1, 2,時, 系統的反應及殘留反應. 
1. Impulse Signal Input時, 會有自己對應的Impluse Response, 再由這個Response去直乘系統0, 1, 2的Response.
2. Impulse Signal Input時, 會得到自己相對單位Impulse Signal的倍數, 去乘單位Impluse Respone, 即得到系統0, 1, ,2的Respone

單位Impulse Siganl [1, 0, 0, 0, ...] -> 單位System Impulse Response -> [4, 2, 1, 0, 0, 0, ...]

非時變的系統特性, Since this is time invariant, that means that I can shift the impulse in time, and the impulse response will shift as well. 
For example, the input [0, 1, 0, 0, 0, ...] will produce [0, 4, 2, 1, 0, 0, ...]. 

線性系統特性, Since the system is linear, that means I can do two things: I can scale the input, and the output will scale the exact same way, and I can add two different inputs, and the output will be the sum of the initial outputs.
For example [1, 2, 0, 0, 0, ...] is two impulses: [1, 0, 0, 0, ...] and 2 * [0, 1, 0, 0, ...], which produces respective outputs [4, 2, 1, 0, 0, ...] and 2 * [0, 4, 2, 1, 0, 0, ...]. We add these together, and we get that the output of [1, 2, 0, 0, ...] is [4, 10, 5, 2, 0, 0, ...]

現在, 我們可以找到任何輸入訊號的輸出. 只需做impluse response shift, multiplying with scaling factor, and add as total
透過上述的方法去得到系統的輸出, 看起來和Convolution似乎沒有關係, 那是因為, 這是在找各個input signal(impluse signal的倍數/延遲)輸入後, 去看整體的輸出. 而不是特定時間點
Now, we can essentially find the output signal for any arbitrary input signal, simply by shifting the impulse response in time, multiplying it by a scaling factor, based on the value of the signal at that time, and adding it to a running total. You might think that this looks nothing like convolution, but bear with me! The reason it looks different is because in this case, you're finding the contribution to the entire output signal of each individual input signal. This is a totally valid way to do this, but very inefficient if you just want to know the value of the output signal at one specific time point.

我們如何在特定的時間點找到輸出信號的值？
好吧，我們知道特定時間點的輸出在這個時間點之前的不同時間（因為系統是因果的）在不同時間的輸入有貢獻。
它從現在正在發生的投入點，從那個時間前的一​​些貢獻，以及之前的時間等等中有一些貢獻，那麼我們如何找到這個貢獻呢？
So let's turn this on its head. How do we find the value of the output signal at a specific time point? Well, we know that the output at a specific time point has contributions from the input at various times from before this time point (since the system is causal). It has some contribution from the input point that is happening now, some contribution from the time before that, and the time before that, etc. So how do we find this contribution?


https://www.quora.com/How-can-I-explain-in-a-simple-manner-what-convolution-is-and-why-it-is-important

Let me put it without much math. Consider multiplication: As and when you get a number, you multiply it by one more number and pass it off as output. A multiplier does not remember stuff. Its like a small child. It forgets all the things you did in the past and responds to the current input. If you smile, it smiles back, so forth. 
But, a convolution is different. It remembers your past actions. Based on that and your present doing, it will decide what to do. If you smile at it and you did real-bad before, it would not smile back at you! 
相乘只是當下, 但, Convolution是含過往記憶(過往殘留效應). 就是符合系統的反應.

https://www.quora.com/How-can-I-explain-in-a-simple-manner-what-convolution-is-and-why-it-is-important
Raeed Chowdhury, Electrical Engineer
它看起來不同的原因是因為在這種情況下，你正在找到每個輸入信號的整個輸出信號的貢獻。但, Convoluation是看某個特定時間點


https://www.quora.com/Digital-Signal-Processing-How-do-you-explain-without-doing-any-calculation-that-convolution-in-time-domain-should-imply-multiplication-in-frequency-domain


https://www.quora.com/What-is-an-intuitive-way-of-explaining-how-the-Fourier-transform-works/answer/Mark-Eichenlaub


https://www.quora.com/Why-do-CNNs-use-convolution-instead-of-cross-correlation
Actually most practical applications of convolutional neural networks (CNN) use cross-correlation instead of convolutions.

Convolution operation either flips the source image or the kernel weights. Flipping actually adds some unnecessary complexity to the CNN code especially that the flipping operation occurs during inference and backpropagation of errors.
On the other hand cross-correlation does not flip the source image or kernel weights. This results in simplified CNN code. Thus cross-correlation is more convenient to implement in CNNs than convolution operation itself.

You can call them that if you want to, but in CNN terms the two are the same. You can do a flip or not, the CNN will just adapt accordingly. If you do a flip then the CNN just learns flipped weights as well so it technically doesn't change anything.


單位脈衝的系統響應會等於它自己
而, 任何的信號都可以拆解為一個個的單位脈衝訊號
因此, 我們將輸入訊號拆解成脈衝訊號的線性關係(加, 減, 乘, 除), 再分別將其對應的脈衝響應作線性組合, 即可得到該輸入訊號的系統響應
在時域, 將輸入訊號拆解成脈衝訊號的線性關係, 再將其對應的脈衝響應以積的方式表示出整體輸出


https://dsp.stackexchange.com/questions/4723/what-is-the-physical-meaning-of-the-convolution-of-two-signals
The input-output behavior of an LTI system can be characterized via its impulse response, and the output of an LTI system for any input signal x(t)x(t) can be expressed as the convolution of the input signal with the system's impulse response.


https://www.quora.com/Digital-Signal-Processing-How-do-you-explain-without-doing-any-calculation-that-convolution-in-time-domain-should-imply-multiplication-in-frequency-domain

http://cc.ee.ntu.edu.tw/~fengli/Teaching/SignalsSystems/

當將兩個多項式相乘時, 其係數的呈現, 即為Convolution的樣式

https://www.allaboutcircuits.com/technical-articles/dsp-applications-of-convolution-part-2/
https://www.allaboutcircuits.com/technical-articles/better-insight-into-dsp-learning-about-convolution/
Any signal can be expressed in terms of unit impulses or dirac-delta functions. (Check out these resources for more information: Signals, Linear Systems, and Convolution and Signals in Natural Domain: Discrete-Time Convolution.)

This fact about signal expression implies that any signal is a series of scaled impulse functions which are shifted in time. However, for each of these impulse functions, we can anticipate the system's behavior, provided we know its impulse response.

As LTI systems obey the law of superposition, we can add all these individual system responses. The result obtained through this process will be the output of the system when the input is fed to it.

convolution can be explained in a similar way even when we deal with it in terms of signals.

This is because the steps involved in convoluting the two signals x1[n] and x2[n] are:

Keep one of the signals—we'll call it x1[n]—as it is while flipping another—we'll call it x2[n]—along its time axis.
Slide x2[n] along x1[n] while multiplying the overlapping samples and summing the product-terms at each time instant.

https://www.dsprelated.com/freebooks/mdft/

A reason for the importance of convolution (defined in §7.2.4) is that every linear time-invariant system8.7can be represented by a convolution. 

https://www.dsprelated.com/freebooks/mdft/Convolution.html
https://www.dsprelated.com/freebooks/mdft/Polynomial_Multiplication.html
https://medium.com/@aiswaryamathur/understanding-fast-fourier-transform-from-scratch-to-solve-polynomial-multiplication-8018d511162f
https://stackoverflow.com/questions/32932245/whats-the-best-way-to-compute-the-coefficients-of-a-polynomial-from-its-roots


